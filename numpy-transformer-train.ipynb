{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280f2210",
   "metadata": {},
   "source": [
    "✅ Summary: What This Code Does\n",
    "\n",
    "* Loads prompt→schema pairs\n",
    "\n",
    "* Builds vocab, prepares model\n",
    "\n",
    "* Trains a transformer to predict columns based on prompt\n",
    "\n",
    "* Generates realistic fake data from schema prediction\n",
    "\n",
    "* Saves model and supports re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87221ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76707cc6",
   "metadata": {},
   "source": [
    "📌 What it does:\n",
    "\n",
    "* `json`: load training data from file.\n",
    "\n",
    "* `pprint`: nicely prints fake data.\n",
    "\n",
    "* `torch`: core PyTorch functionality.\n",
    "\n",
    "* `nn`: contains layers like Embedding, MultiheadAttention, Linear.\n",
    "\n",
    "✅ Example: Prepares you to define a neural network and handle data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf62b7",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ac3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_data.json\") as f:\n",
    "    training_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba30ed59",
   "metadata": {},
   "source": [
    "📌 Loads your training prompts and expected schema columns.\n",
    "\n",
    "✅ Example input (from JSON):\n",
    "\n",
    "```json\n",
    "[\n",
    "  [\"generate a bank dataset\", [\"account_number\", \"name\", \"balance\", \"currency\"]],\n",
    "  [\"create student data\", [\"student_id\", \"name\", \"grade\", \"email\"]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b601b",
   "metadata": {},
   "source": [
    "## Add [CLS] token to prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac49f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    ([\"[CLS]\"] + prompt, columns)\n",
    "    for prompt, columns in training_data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae07ecf",
   "metadata": {},
   "source": [
    "📌 Prepends [CLS] token to every prompt.\n",
    "This acts like a special summary token.\n",
    "\n",
    "✅ Example:\n",
    "\n",
    "```python\n",
    "[\"generate\", \"a\", \"bank\", \"dataset\"] → [\"[CLS]\", \"generate\", \"a\", \"bank\", \"dataset\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126af79",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = set()\n",
    "all_columns = set()\n",
    "for prompt, columns in training_data:\n",
    "    all_tokens.update(prompt)\n",
    "    all_tokens.update(columns)\n",
    "    all_columns.update(columns)\n",
    "vocab = sorted(all_tokens)\n",
    "columns_vocab = sorted(all_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5a2d9",
   "metadata": {},
   "source": [
    "📌 Creates vocabularies of:\n",
    "\n",
    "* All unique words (vocab)\n",
    "\n",
    "* All unique schema fields (columns_vocab)\n",
    "\n",
    "✅ Example:\n",
    "\n",
    "```python\n",
    "vocab = [\"[CLS]\", \"generate\", \"bank\", \"dataset\", ..., \"email\"]\n",
    "columns_vocab = [\"account_number\", \"name\", \"balance\", \"currency\", ..., \"grade\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551df0f7",
   "metadata": {},
   "source": [
    "## Map Words to Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "idx_to_token = {idx: token for token, idx in token_to_idx.items()}\n",
    "column_to_idx = {col: i for i, col in enumerate(columns_vocab)}\n",
    "idx_to_column = {i: col for col, i in column_to_idx.items()}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "num_columns = len(columns_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d50dd24",
   "metadata": {},
   "source": [
    "📌 Creates mappings between tokens and indices for encoding/decoding.\n",
    "\n",
    "✅ Example:\n",
    "\n",
    "```python\n",
    "token_to_idx[\"bank\"] → 4\n",
    "column_to_idx[\"email\"] → 7\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140899a",
   "metadata": {},
   "source": [
    "## Encode Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b293fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(tokens):\n",
    "    return [token_to_idx[t] for t in tokens]\n",
    "\n",
    "def encode_columns(cols):\n",
    "    vec = torch.zeros(num_columns)\n",
    "    for col in cols:\n",
    "        if col in column_to_idx:\n",
    "            vec[column_to_idx[col]] = 1.0\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49270fd6",
   "metadata": {},
   "source": [
    "📌 Converts:\n",
    "\n",
    "* Prompt tokens into integer IDs\n",
    "\n",
    "* Schema column labels into multi-label vectors\n",
    "\n",
    "```python\n",
    "encode([\"[CLS]\", \"generate\", \"bank\"]) → [0, 1, 2]\n",
    "encode_columns([\"account_number\", \"balance\"]) →\n",
    "    tensor([1, 0, 1, 0, ..., 0])  # 1 at relevant column indices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb04c9",
   "metadata": {},
   "source": [
    "## Define Transformer-Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17cd9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, num_labels, embed_dim=64, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(embed_dim)\n",
    "        self.output_proj = nn.Linear(embed_dim, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        attn_output, _ = self.attn(x, x, x)\n",
    "        x = self.ln(x + attn_output)\n",
    "        cls_token = x[:, 0, :]  # use [CLS] token\n",
    "        return self.output_proj(cls_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27af1eac",
   "metadata": {},
   "source": [
    "📌 This model:\n",
    "\n",
    "* Embeds each token (into 64-dim vector)\n",
    "\n",
    "* Applies multi-head self-attention\n",
    "\n",
    "* Uses [CLS] token output to predict schema columns\n",
    "\n",
    "✅ Example:\n",
    "Prompt → embeddings → attention → [CLS] vector → output prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7a430",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3007a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, training_data, epochs=300, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for prompt, cols in training_data:\n",
    "            x = torch.tensor([encode(prompt)], dtype=torch.long)\n",
    "            y = encode_columns(cols).unsqueeze(0)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {total_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fea2d",
   "metadata": {},
   "source": [
    "📌 This function:\n",
    "\n",
    "* Trains your model using **BCEWithLogitsLoss** (multi-label classification)\n",
    "\n",
    "* Compares model predictions to expected schema columns\n",
    "\n",
    "* Uses Adam optimizer\n",
    "\n",
    "✅ Example:\n",
    "\n",
    "```python\n",
    "Prompt: [\"generate\", \"bank\", \"dataset\"]\n",
    "Target: [\"account_number\", \"balance\", \"currency\"]\n",
    "```\n",
    "\n",
    "Model learns to output 1.0 for these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f45bd",
   "metadata": {},
   "source": [
    "## Inference: Predict Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd98b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_columns(model, prompt_tokens, threshold=0.5):\n",
    "    x = torch.tensor([encode([\"[CLS]\"] + prompt_tokens)], dtype=torch.long)\n",
    "    logits = model(x)\n",
    "    probs = torch.sigmoid(logits).squeeze()\n",
    "    pred_indices = (probs > threshold).nonzero(as_tuple=True)[0].tolist()\n",
    "    return [idx_to_column[i] for i in pred_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb0ba8",
   "metadata": {},
   "source": [
    "📌 Takes a user prompt like \"`generate a bank dataset`\", feeds it through the model, and returns column labels where probability > threshold.\n",
    "\n",
    "✅ Example:\n",
    "\n",
    "```python\n",
    "[\"bank\", \"dataset\"] → [\"account_number\", \"name\", \"balance\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9382c33",
   "metadata": {},
   "source": [
    "## Generate Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c6c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_data_utils import FAKE_VALUE_FUNCTIONS, generate_fake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e8eac",
   "metadata": {},
   "source": [
    "📌 Uses dictionary of lambda functions (e.g., fake.name(), fake.iban()) to populate a dataset row-by-row.\n",
    "\n",
    "✅ Example:\n",
    "\n",
    "```python\n",
    "columns = [\"account_number\", \"name\"]\n",
    "→ [[\"DE123...\", \"John Doe\"], [\"GB432...\", \"Alice Smith\"]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f63646",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15b3a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 43.7987\n",
      "Epoch 50: Loss = 0.0124\n",
      "Epoch 100: Loss = 0.0003\n",
      "Epoch 150: Loss = 0.0000\n",
      "Epoch 200: Loss = 0.0000\n",
      "Epoch 250: Loss = 0.0000\n"
     ]
    }
   ],
   "source": [
    "model = SchemaPredictor(vocab_size, num_columns)\n",
    "model = train_model(model, training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf69731",
   "metadata": {},
   "source": [
    "📌 Instantiates and trains your model on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10311bdf",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0078483",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"schema_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd312af2",
   "metadata": {},
   "source": [
    "📌 Saves weights so that can be later loaded without retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e212b1a",
   "metadata": {},
   "source": [
    "## Full Inference Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f6cca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Predicted schema columns: ['member_id', 'membership_status']\n",
      "{'columns': ['member_id', 'membership_status'],\n",
      " 'rows': [['03fff75e-4475-456a-8bf9-c9cc5065caf8', 'active'],\n",
      "          ['82e314da-f918-4392-9c26-c22bf68af4f1', 'active'],\n",
      "          ['8030b490-e90f-46c7-9490-21541179088c', 'inactive'],\n",
      "          ['95ef72bf-f951-4e27-829c-538062874f70', 'inactive'],\n",
      "          ['3d110616-98b9-4571-b0af-7d23d9ee7977', 'inactive']]}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"generate a sport dataset\"\n",
    "tokens = prompt.lower().split()\n",
    "columns = predict_columns(model, tokens, threshold=0.4)\n",
    "columns = [col for col in columns if col in FAKE_VALUE_FUNCTIONS and col not in tokens]\n",
    "columns = list(dict.fromkeys(columns))\n",
    "\n",
    "print(\"🔍 Predicted schema columns:\", columns)\n",
    "pprint(generate_fake_data(columns, n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66db62d",
   "metadata": {},
   "source": [
    "✅ Full example:\n",
    "\n",
    "```json\n",
    "Prompt: \"generate a bank dataset\"\n",
    "→ Predicted: ['account_number', 'balance', 'currency', 'name']\n",
    "→ Fake Data:\n",
    "[\n",
    "  ['GB89...', '1234.56', 'USD', 'Alice'],\n",
    "  ['GB90...', '7823.19', 'EUR', 'Bob'],\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
