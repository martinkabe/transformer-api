{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00f95e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "085b619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTransformer:\n",
    "    def __init__(self, vocab, embed_dim=32):\n",
    "        self.vocab = vocab\n",
    "        self.vocab_size = len(vocab)\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(vocab)}\n",
    "        self.idx_to_token = {idx: token for token, idx in self.token_to_idx.items()}\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embeddings = np.random.randn(self.vocab_size, embed_dim)\n",
    "        self.W_q = np.random.randn(embed_dim, embed_dim)\n",
    "        self.W_k = np.random.randn(embed_dim, embed_dim)\n",
    "        self.W_v = np.random.randn(embed_dim, embed_dim)\n",
    "        self.W_out = np.random.randn(embed_dim, self.vocab_size)\n",
    "\n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=-1, keepdims=True)\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        return [self.token_to_idx.get(token, 0) for token in tokens]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        return [self.idx_to_token.get(idx, \"<unk>\") for idx in indices]\n",
    "\n",
    "    def self_attention(self, x):\n",
    "        Q = x @ self.W_q\n",
    "        K = x @ self.W_k\n",
    "        V = x @ self.W_v\n",
    "        scores = Q @ K.transpose((0, 2, 1)) / np.sqrt(self.embed_dim)\n",
    "        weights = self.softmax(scores)\n",
    "        return weights @ V\n",
    "\n",
    "    def forward(self, prompt_tokens, output_length=4):\n",
    "        idxs = self.encode(prompt_tokens)\n",
    "        x = np.array([self.embeddings[idx] for idx in idxs])[np.newaxis, :, :]\n",
    "        attn_output = self.self_attention(x)\n",
    "        pooled = attn_output.mean(axis=1)\n",
    "        generated = []\n",
    "        for _ in range(output_length):\n",
    "            logits = pooled @ self.W_out\n",
    "            idx = np.argmax(logits, axis=-1)[0]\n",
    "            generated.append(idx)\n",
    "            pooled += self.embeddings[idx]\n",
    "        return self.decode(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "59cdd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\n",
    "    \"bank\", \"school\", \"sport\", \"hospital\", \"company\",\n",
    "    \"account_number\", \"name\", \"balance\", \"currency\",\n",
    "    \"student_id\", \"email\", \"grade\",\n",
    "    \"member_id\", \"sport\", \"membership_status\",\n",
    "    \"patient_id\", \"diagnosis\", \"doctor_name\",\n",
    "    \"employee_id\", \"position\", \"salary\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9344e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "FAKE_VALUE_FUNCTIONS = {\n",
    "    \"name\": lambda: fake.name(),\n",
    "    \"email\": lambda: fake.email(),\n",
    "    \"account_number\": lambda: fake.iban(),\n",
    "    \"balance\": lambda: round(fake.pyfloat(left_digits=5, right_digits=2), 2),\n",
    "    \"currency\": lambda: fake.currency_code(),\n",
    "    \"student_id\": lambda: fake.uuid4(),\n",
    "    \"grade\": lambda: random.choice([\"A\", \"B\", \"C\", \"D\", \"F\"]),\n",
    "    \"sport\": lambda: random.choice([\"football\", \"tennis\", \"basketball\"]),\n",
    "    \"membership_status\": lambda: random.choice([\"active\", \"inactive\"]),\n",
    "    \"patient_id\": lambda: fake.uuid4(),\n",
    "    \"diagnosis\": lambda: random.choice([\"flu\", \"allergy\", \"injury\"]),\n",
    "    \"doctor_name\": lambda: fake.name(),\n",
    "    \"employee_id\": lambda: fake.uuid4(),\n",
    "    \"position\": lambda: random.choice([\"manager\", \"developer\", \"analyst\"]),\n",
    "    \"salary\": lambda: round(fake.pyfloat(left_digits=5, right_digits=2), 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "112cab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_data(columns, n=5):\n",
    "    rows = []\n",
    "    for _ in range(n):\n",
    "        row = [FAKE_VALUE_FUNCTIONS.get(col, lambda: fake.word())() for col in columns]\n",
    "        rows.append(row)\n",
    "    return {\"columns\": columns, \"rows\": rows}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "659e4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"generate a school dataset\"\n",
    "prompt_tokens = prompt.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "487f44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = SimpleTransformer(vocab)\n",
    "predicted_columns = transformer.forward(prompt_tokens, output_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37b84986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Columns: ['patient_id', 'member_id']\n",
      "{'columns': ['patient_id', 'member_id'],\n",
      " 'rows': [['9a61aca4-436d-4542-8507-ccbafdeaa6e9', 'newspaper'],\n",
      "          ['8cbcd555-3c40-4b40-8586-c05efbb6ea93', 'exactly'],\n",
      "          ['fd621e50-3545-42d5-9ffb-e2a29bc7f3be', 'suffer'],\n",
      "          ['381b67fa-5f0f-4fe6-81db-c6c8330bfa61', 'front'],\n",
      "          ['15aa8b52-eb4a-46d3-a736-e7cda98eac99', 'have']]}\n"
     ]
    }
   ],
   "source": [
    "columns = list(dict.fromkeys([\n",
    "    token for token in predicted_columns\n",
    "    if token in vocab and token not in prompt_tokens\n",
    "]))\n",
    "\n",
    "if not columns:\n",
    "    print(\"⚠️ Transformer could not determine valid schema.\")\n",
    "else:\n",
    "    dataset = generate_fake_data(columns, n=5)\n",
    "    print(\"Generated Columns:\", columns)\n",
    "    pprint(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
